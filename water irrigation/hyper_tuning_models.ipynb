{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preproccess_scale_transform(csv_filepath):\n",
    "    dataset = pd.read_csv(csv_filepath)\n",
    "    dataset.drop(\n",
    "        [\n",
    "            \"Date\",\n",
    "            \"SM_2\",\n",
    "            \"SM_8\",\n",
    "            \"SM_20\",\n",
    "            \"SM_40\",\n",
    "            \"ST_2\",\n",
    "            \"ST_8\",\n",
    "            \"ST_20\",\n",
    "            \"ST_40\",\n",
    "            \"solarenergy\",\n",
    "            \"precipprob\",\n",
    "            \"preciptype\",\n",
    "            \"snow\",\n",
    "            \"snowdepth\",\n",
    "            \"windgust\",\n",
    "            \"winddir\",\n",
    "            \"sealevelpressure\",\n",
    "            \"visibility\",\n",
    "            \"solarenergy\",\n",
    "            \"uvindex\",\n",
    "            \"severerisk\",\n",
    "            \"icon\",\n",
    "            \"stations\",\n",
    "            \"dew\",\n",
    "            \"solarradiation\",\n",
    "            \"Time\",\n",
    "            # \"cloudcover\",\n",
    "            \"feelslike\",\n",
    "            # \"windspeed\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "        axis=1,\n",
    "    )\n",
    "    dataset.dropna(inplace=True)\n",
    "\n",
    "    X = dataset.iloc[:, 1:].values\n",
    "    y = dataset.iloc[:, 0].values\n",
    "\n",
    "    ct = ColumnTransformer(\n",
    "        transformers=[(\"encoder\", OneHotEncoder(), [-1])], remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    X = np.array(ct.fit_transform(X))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42\n",
    "    )\n",
    "    sc = MinMaxScaler()\n",
    "    X_train[:, 9:] = sc.fit_transform(X_train[:, 9:])\n",
    "    X_test[:, 9:] = sc.transform(X_test[:, 9:])\n",
    "\n",
    "    X_train, y_train, X_test, y_test = map(\n",
    "        np.asarray, [X_train, y_train, X_test, y_test]\n",
    "    )\n",
    "    X_train, X_test = map(lambda x: x.astype(\"float32\"), [X_train, X_test])\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_preproccess_scale_transform(\n",
    "    \"storage_dataset/prototype_final_dataset.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model \"\"\"\n",
    "ANN_model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(16, activation=\"relu\"),\n",
    "        keras.layers.Dense(8, activation=\"relu\"),\n",
    "        keras.layers.Dense(4, activation=\"relu\"),\n",
    "        keras.layers.Dense(2, activation=\"relu\"),\n",
    "        keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ANN_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.mean_squared_error,\n",
    "    metrics=keras.metrics.mean_absolute_error,\n",
    ")\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "history = ANN_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "ANN_model.summary()\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Increase maximum depth\n",
    "dtr_model = DecisionTreeRegressor(max_depth=10, random_state=0)\n",
    "\n",
    "# Fine-tune hyperparameters\n",
    "dtr_model.fit(X_train, y_train, min_samples_split=20)\n",
    "\n",
    "dtr_ypred = dtr_model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "dtr_mae = mean_absolute_error(y_test, dtr_ypred)\n",
    "dtr_mse = mean_squared_error(y_test, dtr_ypred)\n",
    "print(\"DTR MAE:\", dtr_mae)\n",
    "print(\"DTR MSE:\", dtr_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Try different kernels\n",
    "svr_models = [\n",
    "    SVR(kernel=\"rbf\", C=10, gamma=0.1),\n",
    "    SVR(kernel=\"linear\", C=10),\n",
    "    SVR(kernel=\"poly\", C=10, degree=3),\n",
    "]\n",
    "\n",
    "# Fine-tune hyperparameters\n",
    "for model in svr_models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    svr_ypred = model.predict(X_test)\n",
    "\n",
    "    svr_mae = mean_absolute_error(y_test, svr_ypred)\n",
    "    svr_mse = mean_squared_error(y_test, svr_ypred)\n",
    "\n",
    "    print(f\"SVR {model.kernel} MAE: {svr_mae}, MSE: {svr_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Feature selection using L1 regularization\n",
    "mlr_model = LinearRegression(lasso_lars=True)\n",
    "mlr_model.fit(X_train, y_train)\n",
    "\n",
    "mlr_ypred = mlr_model.predict(X_test)\n",
    "\n",
    "mlr_mae = mean_absolute_error(y_test, mlr_ypred)\n",
    "mlr_mse = mean_squared_error(y_test, mlr_ypred)\n",
    "print(\"MLR MAE:\", mlr_mae)\n",
    "print(\"MLR MSE:\", mlr_mse)\n",
    "\n",
    "# Consider adding polynomial features\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "mlr_model_poly = LinearRegression()\n",
    "mlr_model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "mlr_poly_ypred = mlr_model_poly.predict(X_test_poly)\n",
    "\n",
    "mlr_poly_mae = mean_absolute_error(y_test, mlr_poly_ypred)\n",
    "mlr_poly_mse = mean_squared_error(y_test, mlr_poly_ypred)\n",
    "print(\"MLR with Poly Features MAE:\", mlr_poly_mae)\n",
    "print(\"MLR with Poly Features MSE:\", mlr_poly_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
